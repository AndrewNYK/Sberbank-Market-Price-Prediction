{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product_type_Investment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_3000_price_1500</th>\n",
       "      <th>cafe_count_3000_price_2500</th>\n",
       "      <th>sport_count_3000</th>\n",
       "      <th>office_sqm_5000</th>\n",
       "      <th>cafe_count_5000_na_price</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Bibirevo</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>807385</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>5850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Nagatinskij Zaton</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2690465</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Tekstil'shhiki</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1478160</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>5700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Mitino</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>244166</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>13100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Basmannoe</td>\n",
       "      <td>...</td>\n",
       "      <td>262</td>\n",
       "      <td>149</td>\n",
       "      <td>77</td>\n",
       "      <td>8404624</td>\n",
       "      <td>143</td>\n",
       "      <td>319</td>\n",
       "      <td>17</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>16331452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30466</th>\n",
       "      <td>44</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Otradnoe</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>838601</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>7400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30467</th>\n",
       "      <td>86</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Tverskoe</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>155</td>\n",
       "      <td>80</td>\n",
       "      <td>9949843</td>\n",
       "      <td>136</td>\n",
       "      <td>313</td>\n",
       "      <td>24</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>25000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30468</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Vnukovskoe</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>117300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>6970959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30469</th>\n",
       "      <td>64</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Obruchevskoe</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>1225712</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>13500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>43</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Novogireevo</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>351244</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>5600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30471 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq  life_sq  floor  max_floor  build_year  num_room  kitch_sq  \\\n",
       "0           43     27.0    4.0        NaN         NaN       NaN       NaN   \n",
       "1           34     19.0    3.0        NaN         NaN       NaN       NaN   \n",
       "2           43     29.0    2.0        NaN         NaN       NaN       NaN   \n",
       "3           89     50.0    9.0        NaN         NaN       NaN       NaN   \n",
       "4           77     77.0    4.0        NaN         NaN       NaN       NaN   \n",
       "...        ...      ...    ...        ...         ...       ...       ...   \n",
       "30466       44     27.0    7.0        9.0      1975.0       2.0       6.0   \n",
       "30467       86     59.0    3.0        9.0      1935.0       4.0      10.0   \n",
       "30468       45      NaN   10.0       20.0         NaN       1.0       1.0   \n",
       "30469       64     32.0    5.0       15.0      2003.0       2.0      11.0   \n",
       "30470       43     28.0    1.0        9.0      1968.0       2.0       6.0   \n",
       "\n",
       "       state   product_type              sub_area  ...  \\\n",
       "0        NaN     Investment              Bibirevo  ...   \n",
       "1        NaN     Investment     Nagatinskij Zaton  ...   \n",
       "2        NaN     Investment        Tekstil'shhiki  ...   \n",
       "3        NaN     Investment                Mitino  ...   \n",
       "4        NaN     Investment             Basmannoe  ...   \n",
       "...      ...            ...                   ...  ...   \n",
       "30466    3.0     Investment              Otradnoe  ...   \n",
       "30467    3.0     Investment              Tverskoe  ...   \n",
       "30468    1.0  OwnerOccupier  Poselenie Vnukovskoe  ...   \n",
       "30469    2.0     Investment          Obruchevskoe  ...   \n",
       "30470    2.0     Investment           Novogireevo  ...   \n",
       "\n",
       "       cafe_count_3000_price_1500  cafe_count_3000_price_2500  \\\n",
       "0                              16                           3   \n",
       "1                               4                           2   \n",
       "2                               9                           3   \n",
       "3                              10                           3   \n",
       "4                             262                         149   \n",
       "...                           ...                         ...   \n",
       "30466                          15                           5   \n",
       "30467                         230                         155   \n",
       "30468                           2                           1   \n",
       "30469                          26                          13   \n",
       "30470                           6                           2   \n",
       "\n",
       "       sport_count_3000  office_sqm_5000  cafe_count_5000_na_price  \\\n",
       "0                    21           807385                        12   \n",
       "1                    19          2690465                         9   \n",
       "2                    20          1478160                        10   \n",
       "3                    18           244166                         4   \n",
       "4                    77          8404624                       143   \n",
       "...                 ...              ...                       ...   \n",
       "30466                29           838601                        18   \n",
       "30467                80          9949843                       136   \n",
       "30468                 6           117300                         1   \n",
       "30469                33          1225712                        11   \n",
       "30470                26           351244                         3   \n",
       "\n",
       "       cafe_count_5000_price_2500  cafe_count_5000_price_high  year  month  \\\n",
       "0                               9                           0  2011      8   \n",
       "1                              15                           0  2011      8   \n",
       "2                              10                           0  2011      8   \n",
       "3                              11                           1  2011      9   \n",
       "4                             319                          17  2011      9   \n",
       "...                           ...                         ...   ...    ...   \n",
       "30466                          15                           0  2015      6   \n",
       "30467                         313                          24  2015      6   \n",
       "30468                           1                           0  2015      6   \n",
       "30469                          22                           1  2015      6   \n",
       "30470                           5                           0  2015      6   \n",
       "\n",
       "       price_doc  \n",
       "0        5850000  \n",
       "1        6000000  \n",
       "2        5700000  \n",
       "3       13100000  \n",
       "4       16331452  \n",
       "...          ...  \n",
       "30466    7400000  \n",
       "30467   25000000  \n",
       "30468    6970959  \n",
       "30469   13500000  \n",
       "30470    5600000  \n",
       "\n",
       "[30471 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import top_40_cols\n",
    "\n",
    "df = pd.read_csv('../Dataset/train.csv/train.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "df.drop(['timestamp'], axis=1, inplace=True)\n",
    "target = df['price_doc']\n",
    "\n",
    "columns_to_drop = [column for column in df.columns if column not in top_40_cols]\n",
    "df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "missing_column = [column for column in top_40_cols if column not in df.columns]\n",
    "print(missing_column)\n",
    "df['price_doc'] = target\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NAN:  ['life_sq', 'floor', 'max_floor', 'build_year', 'num_room', 'kitch_sq', 'state', 'metro_min_walk']\n",
      "Columns with NAN:  ['floor', 'max_floor', 'build_year', 'num_room', 'kitch_sq', 'state', 'metro_min_walk']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns with NAN: \", df.columns[df.isna().any()].tolist())\n",
    "# columns with NAN are ['life_sq', 'floor', 'max_floor', 'build_year', 'num_room', 'kitch_sq', 'state', 'metro_min_walk']\n",
    "# first step is to fill in NaN columns with some values.\n",
    "# we take different approaches for different columns\n",
    "\n",
    "# For life_sq, I think it is acceptable that we replace NaN values with the full_sq values of those rows\n",
    "df['life_sq'].fillna(df['full_sq'], inplace=True)\n",
    "print(\"Columns with NAN: \", df.columns[df.isna().any()].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 30, 52, 80, inf]\n",
      "Index(['Ajeroport', 'Akademicheskoe', 'Alekseevskoe', 'Altuf'evskoe', 'Arbat',\n",
      "       'Babushkinskoe', 'Basmannoe', 'Begovoe', 'Beskudnikovskoe', 'Bibirevo',\n",
      "       ...\n",
      "       'Vnukovo', 'Vojkovskoe', 'Vostochnoe', 'Vostochnoe Degunino',\n",
      "       'Vostochnoe Izmajlovo', 'Vyhino-Zhulebino', 'Zamoskvorech'e',\n",
      "       'Zapadnoe Degunino', 'Zjablikovo', 'Zjuzino'],\n",
      "      dtype='object', name='sub_area', length=146)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:86: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  num_room_averages = df.groupby('full_sq_bins')['num_room'].transform(lambda x: np.ceil(x.mean()))\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:204: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.ceil(row['life_sq'] * sub_area_avg[sub_area])\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df[c]\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df[c]\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df[c]\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df[c]\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df[c]\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df[c]\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df[c]\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df[c]\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df_no_outliers[c].astype('category')\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df_no_outliers[c].astype('category')\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers[c] = df_no_outliers[c].astype('category')\n",
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_outliers['price_doc'] = df[\"price_doc\"] * .969 + 10\n"
     ]
    }
   ],
   "source": [
    "from utils import preprocess_train\n",
    "\n",
    "df_no_outliers = preprocess_train(df)\n",
    "\n",
    "\n",
    "# # drop rows where life_sq and kitch_sq higher than full_sq\n",
    "# df = df.drop(df[(df['full_sq'] <= df['life_sq'])].index)\n",
    "# df = df.drop(df[(df['full_sq'] <= df['kitch_sq'])].index)\n",
    "\n",
    "# # for max_floor, we could fill NaN with the median max_floor of properties in the same sub_area\n",
    "# sub_area_medians = df.groupby('sub_area')['max_floor'].median().reset_index()\n",
    "# # sub_area_medians['max_floor'] = np.ceil(sub_area_medians['max_floor'])\n",
    "# df = df.merge(sub_area_medians, on='sub_area', suffixes=('', '_median'), how='left')\n",
    "# df['max_floor'].fillna(df['max_floor_median'], inplace=True)\n",
    "# df.drop(columns='max_floor_median', inplace=True)\n",
    "\n",
    "# # and then for floor, we just fill NaN with the max_floor\n",
    "# df['floor'].fillna(df['max_floor'], inplace=True)\n",
    "\n",
    "# # finally we replace the max_floor with the floor, if there are any value of floor greater than max_floor(e.g row 63)\n",
    "# df['max_floor'] = df.apply(lambda row: row['floor'] if row['floor'] > row['max_floor'] else row['max_floor'], axis=1)\n",
    "\n",
    "# # we do the same for build_year, fill NaN with the median build_year of properties in the same sub_area\n",
    "# sub_area_medians = df.groupby('sub_area')['build_year'].median().reset_index()\n",
    "# # sub_area_medians['build_year'] = np.ceil(sub_area_medians['build_year'])\n",
    "# df = df.merge(sub_area_medians, on='sub_area', suffixes=('', '_median'), how='left')\n",
    "# df['build_year'].fillna(df['build_year_median'], inplace=True)\n",
    "# df.drop(columns='build_year_median', inplace=True)\n",
    "\n",
    "# # for num_room, we shall split the data into different ranges of full_sq value and calculate the average num_room for each range\n",
    "# # then, we replace the num_room NaN values depending on which range the row's full_sq belongs to\n",
    "# # Define the ranges for 'full_sq' bins\n",
    "# bins = [0, 30, 52, 80, float('inf')]  # these values are eyeballed\n",
    "# print(bins)\n",
    "\n",
    "# # Use pd.cut to create bins for 'full_sq'\n",
    "# df['full_sq_bins'] = pd.cut(df['full_sq'], bins=bins)\n",
    "\n",
    "# # Calculate the average 'num_room' for each 'full_sq' range\n",
    "# # num_room_averages = df.groupby('full_sq_bins')['num_room'].transform('mean')\n",
    "# num_room_averages = df.groupby('full_sq_bins')['num_room'].transform(lambda x: np.ceil(x.mean()))\n",
    "# df['num_room'].fillna(num_room_averages, inplace=True)\n",
    "# df.drop(columns='full_sq_bins', inplace=True)\n",
    "\n",
    "# # for kitch_sq, we shall group by sub_area and calculate the average kitch_sq/life_sq proportion, then replace NaN values with the proporiton multiplied by life_sq\n",
    "# # Calculate the 'kitch_sq/life_sq' for each row\n",
    "# df['kitch_sq_per_life_sq'] = df['kitch_sq'] / df['life_sq']\n",
    "\n",
    "# # Calculate the average 'kitch_sq/life_sq' for each 'sub_area'\n",
    "# sub_area_avg = df.groupby('sub_area')['kitch_sq_per_life_sq'].mean()\n",
    "\n",
    "# # Define a function to fill NaN values in 'kitch_sq' based on 'sub_area'\n",
    "# def fill_kitch_sq(row):\n",
    "#     sub_area = row['sub_area']\n",
    "#     if pd.notna(row['kitch_sq']):\n",
    "#         return row['kitch_sq']\n",
    "#     if sub_area in sub_area_avg:\n",
    "#         return np.ceil(row['life_sq'] * sub_area_avg[sub_area])\n",
    "#     return row['kitch_sq']\n",
    "\n",
    "# # Apply the function to fill NaN values in 'kitch_sq'\n",
    "# df['kitch_sq'] = df.apply(fill_kitch_sq, axis=1)\n",
    "\n",
    "# # Drop the 'kitch_sq_per_life_sq' column if you no longer need it\n",
    "# df.drop(columns='kitch_sq_per_life_sq', inplace=True)\n",
    "\n",
    "# # we do the same for state, fill NaN with the median state of properties in the same sub_area\n",
    "# sub_area_medians = df.groupby('sub_area')['state'].median().reset_index()\n",
    "# # sub_area_medians['build_year'] = np.ceil(sub_area_medians['build_year'])\n",
    "# df = df.merge(sub_area_medians, on='sub_area', suffixes=('', '_median'), how='left')\n",
    "# df['state'].fillna(df['state_median'], inplace=True)\n",
    "# df.drop(columns='state_median', inplace=True)\n",
    "\n",
    "categorical_cols = ['floor', 'max_floor', 'state', 'product_type', 'sub_area', 'num_room', 'year', 'month']\n",
    "\n",
    "# def remove_outliers_iqr(df):\n",
    "#     Q1 = df.quantile(0.25)\n",
    "#     Q3 = df.quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     return df[~((df < lower_bound) | (df > upper_bound)).any(axis=1)]\n",
    "\n",
    "# df_drop_categorical = df.drop(columns=categorical_cols, axis=1)\n",
    "# # Remove rows with outliers\n",
    "# df_no_outliers = remove_outliers_iqr(df_drop_categorical)\n",
    "# # scaler = StandardScaler()\n",
    "# # df_no_outliers_scaled = scaler.fit_transform(df_no_outliers)\n",
    "# display(df_no_outliers)\n",
    "\n",
    "# for c in categorical_cols:\n",
    "#     df_no_outliers[c] = df[c]\n",
    "\n",
    "# print(\"Columns with NAN: \", df_no_outliers.columns[df_no_outliers.isna().any()].tolist())\n",
    "# print(\"Num NANs: \", df_no_outliers.isnull().sum().sum())\n",
    "\n",
    "# for c in categorical_cols:\n",
    "#     df_no_outliers[c] = df_no_outliers[c].astype('category')\n",
    "\n",
    "# df_no_outliers['price_doc'] = df[\"price_doc\"] * .969 + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# display(df[df['sub_area'] == 'Novogireevo'])\n",
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define a function to remove rows with outliers based on the IQR\n",
    "# def remove_outliers_iqr(df):\n",
    "#     Q1 = df.quantile(0.25)\n",
    "#     Q3 = df.quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     return df[~((df < lower_bound) | (df > upper_bound)).any(axis=1)]\n",
    "\n",
    "# df_drop_categorical = df.drop(columns=categorical_cols, axis=1)\n",
    "# # Remove rows with outliers\n",
    "# df_no_outliers = remove_outliers_iqr(df_drop_categorical)\n",
    "# # scaler = StandardScaler()\n",
    "# # df_no_outliers_scaled = scaler.fit_transform(df_no_outliers)\n",
    "# display(df_no_outliers)\n",
    "\n",
    "# for c in categorical_cols:\n",
    "#     df_no_outliers[c] = df[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>build_year</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>metro_min_avto</th>\n",
       "      <th>metro_km_avto</th>\n",
       "      <th>metro_min_walk</th>\n",
       "      <th>kindergarten_km</th>\n",
       "      <th>green_zone_km</th>\n",
       "      <th>industrial_km</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>price_doc</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>state</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>num_room</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.590241</td>\n",
       "      <td>1.131260</td>\n",
       "      <td>13.575119</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.600973</td>\n",
       "      <td>1.080934</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5668660.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Bibirevo</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.936700</td>\n",
       "      <td>0.647337</td>\n",
       "      <td>7.620630</td>\n",
       "      <td>0.147754</td>\n",
       "      <td>0.065321</td>\n",
       "      <td>0.966479</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5814010.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Nagatinskij Zaton</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.120999</td>\n",
       "      <td>1.637996</td>\n",
       "      <td>17.351515</td>\n",
       "      <td>0.049102</td>\n",
       "      <td>0.453172</td>\n",
       "      <td>0.939275</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5523310.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Tekstil'shhiki</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1967.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.175431</td>\n",
       "      <td>1.338707</td>\n",
       "      <td>14.742289</td>\n",
       "      <td>0.112905</td>\n",
       "      <td>0.148957</td>\n",
       "      <td>0.670432</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5135710.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Koptevo</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.383373</td>\n",
       "      <td>0.396275</td>\n",
       "      <td>4.755297</td>\n",
       "      <td>0.309673</td>\n",
       "      <td>0.191191</td>\n",
       "      <td>2.024971</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1938010.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Kuncevo</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21265</th>\n",
       "      <td>52</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.207656</td>\n",
       "      <td>0.695893</td>\n",
       "      <td>8.350721</td>\n",
       "      <td>0.621263</td>\n",
       "      <td>0.079039</td>\n",
       "      <td>0.547333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>969010.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Mitino</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21271</th>\n",
       "      <td>56</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.622565</td>\n",
       "      <td>1.580238</td>\n",
       "      <td>8.510351</td>\n",
       "      <td>0.225720</td>\n",
       "      <td>0.349807</td>\n",
       "      <td>1.646417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11628010.00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Severnoe Tushino</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21272</th>\n",
       "      <td>56</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815305</td>\n",
       "      <td>0.652244</td>\n",
       "      <td>7.447930</td>\n",
       "      <td>0.414927</td>\n",
       "      <td>0.143626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9943897.69</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Sviblovo</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21273</th>\n",
       "      <td>44</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.384021</td>\n",
       "      <td>0.659002</td>\n",
       "      <td>8.158093</td>\n",
       "      <td>0.132645</td>\n",
       "      <td>0.139814</td>\n",
       "      <td>0.702853</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7170610.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Otradnoe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21276</th>\n",
       "      <td>43</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.584636</td>\n",
       "      <td>0.454650</td>\n",
       "      <td>5.455795</td>\n",
       "      <td>0.093619</td>\n",
       "      <td>0.559699</td>\n",
       "      <td>0.455194</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5426410.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Novogireevo</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10836 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq  life_sq  build_year  kitch_sq  metro_min_avto  metro_km_avto  \\\n",
       "0           43     27.0      1976.0       8.0        2.590241       1.131260   \n",
       "1           34     19.0      1982.0       6.0        0.936700       0.647337   \n",
       "2           43     29.0      1969.0       9.0        2.120999       1.637996   \n",
       "6           42     27.0      1967.5       8.0        2.175431       1.338707   \n",
       "7           36     21.0      1980.0       7.0        1.383373       0.396275   \n",
       "...        ...      ...         ...       ...             ...            ...   \n",
       "21265       52     30.0      1992.0       8.0        1.207656       0.695893   \n",
       "21271       56     29.0      2001.0      11.0        2.622565       1.580238   \n",
       "21272       56     51.0      2017.0       1.0        0.815305       0.652244   \n",
       "21273       44     27.0      1975.0       6.0        1.384021       0.659002   \n",
       "21276       43     28.0      1968.0       6.0        0.584636       0.454650   \n",
       "\n",
       "       metro_min_walk  kindergarten_km  green_zone_km  industrial_km  ...  \\\n",
       "0           13.575119         0.145700       0.600973       1.080934  ...   \n",
       "1            7.620630         0.147754       0.065321       0.966479  ...   \n",
       "2           17.351515         0.049102       0.453172       0.939275  ...   \n",
       "6           14.742289         0.112905       0.148957       0.670432  ...   \n",
       "7            4.755297         0.309673       0.191191       2.024971  ...   \n",
       "...               ...              ...            ...            ...  ...   \n",
       "21265        8.350721         0.621263       0.079039       0.547333  ...   \n",
       "21271        8.510351         0.225720       0.349807       1.646417  ...   \n",
       "21272        7.447930         0.414927       0.143626       0.000000  ...   \n",
       "21273        8.158093         0.132645       0.139814       0.702853  ...   \n",
       "21276        5.455795         0.093619       0.559699       0.455194  ...   \n",
       "\n",
       "       cafe_count_5000_price_high    price_doc  floor  max_floor  state  \\\n",
       "0                               0   5668660.00    4.0       12.0    2.0   \n",
       "1                               0   5814010.00    3.0       16.0    2.0   \n",
       "2                               0   5523310.00    2.0        9.0    2.0   \n",
       "6                               1   5135710.00    5.0        9.0    2.0   \n",
       "7                               0   1938010.00    9.0       12.0    2.0   \n",
       "...                           ...          ...    ...        ...    ...   \n",
       "21265                           1    969010.00    8.0       14.0    2.0   \n",
       "21271                           0  11628010.00   13.0       14.0    3.0   \n",
       "21272                           0   9943897.69   19.0       19.0    1.0   \n",
       "21273                           0   7170610.00    7.0        9.0    3.0   \n",
       "21276                           0   5426410.00    1.0        9.0    2.0   \n",
       "\n",
       "        product_type           sub_area  num_room  year  month  \n",
       "0         Investment           Bibirevo       2.0  2011      8  \n",
       "1         Investment  Nagatinskij Zaton       2.0  2011      8  \n",
       "2         Investment     Tekstil'shhiki       2.0  2011      8  \n",
       "6         Investment            Koptevo       2.0  2011      9  \n",
       "7         Investment            Kuncevo       2.0  2011      9  \n",
       "...              ...                ...       ...   ...    ...  \n",
       "21265     Investment             Mitino       2.0  2015      6  \n",
       "21271     Investment   Severnoe Tushino       2.0  2015      6  \n",
       "21272  OwnerOccupier           Sviblovo       2.0  2015      6  \n",
       "21273     Investment           Otradnoe       2.0  2015      6  \n",
       "21276     Investment        Novogireevo       2.0  2015      6  \n",
       "\n",
       "[10836 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_no_outliers)\n",
    "# df_no_outliers.to_csv('processed_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\4056805904.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2170894.9642047808\n",
      "R2: 0.36502090298518786\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error, r2_score, mean_squared_error\n",
    "\n",
    "y = df_no_outliers['price_doc']\n",
    "X = df_no_outliers.drop(columns='price_doc', axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "one_hot_encoder.fit(X_train[categorical_cols])\n",
    "\n",
    "feature_names = one_hot_encoder.get_feature_names_out(input_features=categorical_cols)\n",
    "\n",
    "X_train[feature_names] = one_hot_encoder.transform(X_train[categorical_cols])\n",
    "X_test[feature_names] = one_hot_encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "X_train = X_train.drop(categorical_cols, axis=1)\n",
    "X_test = X_test.drop(categorical_cols, axis=1)\n",
    "\n",
    "\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "\n",
    "# te_encoder = TargetEncoder(cols=categorical_cols, min_samples_leaf=5, smoothing=8)\n",
    "\n",
    "# # Fit the encoder on the encoding split.\n",
    "# te_encoder.fit(X_train, y_train)\n",
    "\n",
    "# for c in categorical_cols:\n",
    "#     X_train[c] = te_encoder.transform(X_train)[c]\n",
    "#     X_test[c] = te_encoder.transform(X_test)[c]\n",
    "\n",
    "train_data = xgboost.DMatrix(X_train, label=y_train)\n",
    "test_data = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'auto',\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.05\n",
    "}\n",
    "\n",
    "n = 100\n",
    "model = xgboost.train(\n",
    "    params=params,\n",
    "    dtrain=train_data,\n",
    "    num_boost_round=n,\n",
    "    )\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "\n",
    "rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 30, 52, 80, inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yu_Hao\\Desktop\\Y4S1\\CZ4041 ML\\CZ4041-Sterbank-Market\\preprocessing\\utils.py:163: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  num_room_averages = df.groupby('full_sq_bins')['num_room'].transform(lambda x: np.ceil(x.mean()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_3000</th>\n",
       "      <th>cafe_count_3000_price_1500</th>\n",
       "      <th>cafe_count_3000_price_2500</th>\n",
       "      <th>sport_count_3000</th>\n",
       "      <th>office_sqm_5000</th>\n",
       "      <th>cafe_count_5000_na_price</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.00</td>\n",
       "      <td>20.70</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Juzhnoe Butovo</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>37550</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.20</td>\n",
       "      <td>79.20</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Vnukovskoe</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>177300</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.50</td>\n",
       "      <td>25.10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Perovo</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>427889</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.80</td>\n",
       "      <td>36.00</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Voskresenskoe</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Vnukovskoe</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>117300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>52.20</td>\n",
       "      <td>31.80</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Kon'kovo</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1742694</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>54.09</td>\n",
       "      <td>54.09</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Desjonovskoe</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td>41.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Tverskoe</td>\n",
       "      <td>...</td>\n",
       "      <td>1815</td>\n",
       "      <td>446</td>\n",
       "      <td>255</td>\n",
       "      <td>88</td>\n",
       "      <td>9997846</td>\n",
       "      <td>170</td>\n",
       "      <td>371</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660</th>\n",
       "      <td>34.80</td>\n",
       "      <td>19.80</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Orehovo-Borisovo Juzhnoe</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>54500</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>63.00</td>\n",
       "      <td>43.80</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Chertanovo Severnoe</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>1662474</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7662 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      full_sq  life_sq  floor  max_floor  build_year  num_room  kitch_sq  \\\n",
       "0       39.00    20.70      2          9      1998.0         1       8.9   \n",
       "1       79.20    79.20      8         17         0.0         3       1.0   \n",
       "2       40.50    25.10      3          5      1960.0         2       4.8   \n",
       "3       62.80    36.00     17         17      2016.0         2      62.8   \n",
       "4       40.00    40.00     17         17         0.0         1       1.0   \n",
       "...       ...      ...    ...        ...         ...       ...       ...   \n",
       "7657    52.20    31.80     10         12      1973.0         2       9.1   \n",
       "7658    54.09    54.09     14         14      2016.0         2       0.0   \n",
       "7659    41.08     1.00     12         12         1.0         1       1.0   \n",
       "7660    34.80    19.80      8          9      1977.0         1       6.4   \n",
       "7661    63.00    43.80      5          5      1973.0         3       7.1   \n",
       "\n",
       "      state   product_type                  sub_area  ...  cafe_count_3000  \\\n",
       "0       3.0     Investment            Juzhnoe Butovo  ...               12   \n",
       "1       1.0  OwnerOccupier      Poselenie Vnukovskoe  ...               10   \n",
       "2       2.0     Investment                    Perovo  ...               37   \n",
       "3       3.0  OwnerOccupier   Poselenie Voskresenskoe  ...                1   \n",
       "4       1.0  OwnerOccupier      Poselenie Vnukovskoe  ...                9   \n",
       "...     ...            ...                       ...  ...              ...   \n",
       "7657    2.0     Investment                  Kon'kovo  ...               91   \n",
       "7658    1.0  OwnerOccupier    Poselenie Desjonovskoe  ...                2   \n",
       "7659    1.0  OwnerOccupier                  Tverskoe  ...             1815   \n",
       "7660    2.0     Investment  Orehovo-Borisovo Juzhnoe  ...               50   \n",
       "7661    3.0     Investment       Chertanovo Severnoe  ...               76   \n",
       "\n",
       "      cafe_count_3000_price_1500  cafe_count_3000_price_2500  \\\n",
       "0                              7                           0   \n",
       "1                              2                           1   \n",
       "2                              7                           2   \n",
       "3                              0                           0   \n",
       "4                              2                           1   \n",
       "...                          ...                         ...   \n",
       "7657                          25                           7   \n",
       "7658                           1                           0   \n",
       "7659                         446                         255   \n",
       "7660                           9                           4   \n",
       "7661                          17                           6   \n",
       "\n",
       "      sport_count_3000  office_sqm_5000  cafe_count_5000_na_price  \\\n",
       "0                    7            37550                         2   \n",
       "1                    7           177300                         2   \n",
       "2                   22           427889                         5   \n",
       "3                    0                0                         0   \n",
       "4                    6           117300                         1   \n",
       "...                ...              ...                       ...   \n",
       "7657                20          1742694                        15   \n",
       "7658                 0                0                         0   \n",
       "7659                88          9997846                       170   \n",
       "7660                16            54500                        10   \n",
       "7661                24          1662474                        11   \n",
       "\n",
       "      cafe_count_5000_price_2500  cafe_count_5000_price_high  year  month  \n",
       "0                              0                           0  2015      7  \n",
       "1                              1                           0  2015      7  \n",
       "2                             11                           0  2015      7  \n",
       "3                              1                           0  2015      7  \n",
       "4                              1                           0  2015      7  \n",
       "...                          ...                         ...   ...    ...  \n",
       "7657                          28                           1  2016      5  \n",
       "7658                           2                           0  2016      5  \n",
       "7659                         371                          26  2016      5  \n",
       "7660                           7                           0  2016      5  \n",
       "7661                          11                           0  2016      5  \n",
       "\n",
       "[7662 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING ON ACTUAL TEST DATA FROM HERE\n",
    "from utils import preprocess_test\n",
    "test_df = pd.read_csv('../Dataset/test.csv/test.csv')\n",
    "df = test_df.copy()\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "df.drop(['timestamp'], axis=1, inplace=True)\n",
    "\n",
    "columns_to_drop = [column for column in df.columns if column not in top_40_cols]\n",
    "df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "# missing_column = [column for column in top_40_cols if column not in df.columns]\n",
    "# print(missing_column)\n",
    "# drop rows where life_sq and kitch_sq higher than full_sq\n",
    "# df = df.drop(df[(df['full_sq'] <= df['life_sq'])].index)\n",
    "# df = df.drop(df[(df['full_sq'] <= df['kitch_sq'])].index)\n",
    "\n",
    "df = preprocess_test(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For life_sq, I think it is acceptable that we replace NaN values with the full_sq values of those rows\n",
    "# df['life_sq'].fillna(df['full_sq'], inplace=True)\n",
    "\n",
    "# # for max_floor, we could fill NaN with the median max_floor of properties in the same sub_area\n",
    "# sub_area_medians = df.groupby('sub_area')['max_floor'].median().reset_index()\n",
    "# # sub_area_medians['max_floor'] = np.ceil(sub_area_medians['max_floor'])\n",
    "# df = df.merge(sub_area_medians, on='sub_area', suffixes=('', '_median'), how='left')\n",
    "# df['max_floor'].fillna(df['max_floor_median'], inplace=True)\n",
    "# df.drop(columns='max_floor_median', inplace=True)\n",
    "\n",
    "# # and then for floor, we just fill NaN with the max_floor\n",
    "# df['floor'].fillna(df['max_floor'], inplace=True)\n",
    "\n",
    "# # finally we replace the max_floor with the floor, if there are any value of floor greater than max_floor(e.g row 63)\n",
    "# df['max_floor'] = df.apply(lambda row: row['floor'] if row['floor'] > row['max_floor'] else row['max_floor'], axis=1)\n",
    "\n",
    "# # we do the same for build_year, fill NaN with the median build_year of properties in the same sub_area\n",
    "# sub_area_medians = df.groupby('sub_area')['build_year'].median().reset_index()\n",
    "# # sub_area_medians['build_year'] = np.ceil(sub_area_medians['build_year'])\n",
    "# df = df.merge(sub_area_medians, on='sub_area', suffixes=('', '_median'), how='left')\n",
    "# df['build_year'].fillna(df['build_year_median'], inplace=True)\n",
    "# df.drop(columns='build_year_median', inplace=True)\n",
    "\n",
    "# # for num_room, we shall split the data into different ranges of full_sq value and calculate the average num_room for each range\n",
    "# # then, we replace the num_room NaN values depending on which range the row's full_sq belongs to\n",
    "# # Define the ranges for 'full_sq' bins\n",
    "# bins = [0, 30, 52, 80, float('inf')]  # these values are eyeballed\n",
    "# print(bins)\n",
    "\n",
    "# # Use pd.cut to create bins for 'full_sq'\n",
    "# df['full_sq_bins'] = pd.cut(df['full_sq'], bins=bins)\n",
    "\n",
    "# # Calculate the average 'num_room' for each 'full_sq' range\n",
    "# # num_room_averages = df.groupby('full_sq_bins')['num_room'].transform('mean')\n",
    "# num_room_averages = df.groupby('full_sq_bins')['num_room'].transform(lambda x: np.ceil(x.mean()))\n",
    "# df['num_room'].fillna(num_room_averages, inplace=True)\n",
    "# df.drop(columns='full_sq_bins', inplace=True)\n",
    "\n",
    "# # for kitch_sq, we shall group by sub_area and calculate the average kitch_sq/life_sq proportion, then replace NaN values with the proporiton multiplied by life_sq\n",
    "# # Calculate the 'kitch_sq/life_sq' for each row\n",
    "# df['kitch_sq_per_life_sq'] = df['kitch_sq'] / df['life_sq']\n",
    "\n",
    "# # Calculate the average 'kitch_sq/life_sq' for each 'sub_area'\n",
    "# sub_area_avg = df.groupby('sub_area')['kitch_sq_per_life_sq'].mean()\n",
    "\n",
    "# # Apply the function to fill NaN values in 'kitch_sq'\n",
    "# df['kitch_sq'] = df.apply(fill_kitch_sq, axis=1)\n",
    "\n",
    "# # Drop the 'kitch_sq_per_life_sq' column if you no longer need it\n",
    "# df.drop(columns='kitch_sq_per_life_sq', inplace=True)\n",
    "\n",
    "# # we do the same for state, fill NaN with the median state of properties in the same sub_area\n",
    "# sub_area_medians = df.groupby('sub_area')['state'].median().reset_index()\n",
    "# # sub_area_medians['build_year'] = np.ceil(sub_area_medians['build_year'])\n",
    "# df = df.merge(sub_area_medians, on='sub_area', suffixes=('', '_median'), how='left')\n",
    "# df['state'].fillna(df['state_median'], inplace=True)\n",
    "# df.drop(columns='state_median', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>build_year</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>metro_min_avto</th>\n",
       "      <th>metro_km_avto</th>\n",
       "      <th>metro_min_walk</th>\n",
       "      <th>kindergarten_km</th>\n",
       "      <th>green_zone_km</th>\n",
       "      <th>industrial_km</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>state</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>num_room</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.00</td>\n",
       "      <td>20.70</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.258957</td>\n",
       "      <td>0.735908</td>\n",
       "      <td>8.830901</td>\n",
       "      <td>0.078502</td>\n",
       "      <td>0.061485</td>\n",
       "      <td>1.205404</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Juzhnoe Butovo</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.20</td>\n",
       "      <td>79.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.230425</td>\n",
       "      <td>3.444625</td>\n",
       "      <td>41.335498</td>\n",
       "      <td>1.192193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.742377</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Vnukovskoe</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.50</td>\n",
       "      <td>25.10</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.585306</td>\n",
       "      <td>1.122214</td>\n",
       "      <td>13.466563</td>\n",
       "      <td>0.065324</td>\n",
       "      <td>0.580638</td>\n",
       "      <td>0.900408</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Perovo</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.80</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7.931398</td>\n",
       "      <td>6.038848</td>\n",
       "      <td>68.559794</td>\n",
       "      <td>3.189083</td>\n",
       "      <td>0.025446</td>\n",
       "      <td>0.466738</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Voskresenskoe</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.152792</td>\n",
       "      <td>1.722233</td>\n",
       "      <td>20.666800</td>\n",
       "      <td>0.897889</td>\n",
       "      <td>0.427248</td>\n",
       "      <td>0.353642</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Vnukovskoe</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>52.20</td>\n",
       "      <td>31.80</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.789207</td>\n",
       "      <td>1.179312</td>\n",
       "      <td>13.968183</td>\n",
       "      <td>0.334653</td>\n",
       "      <td>0.199909</td>\n",
       "      <td>0.624466</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Kon'kovo</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>54.09</td>\n",
       "      <td>54.09</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.839451</td>\n",
       "      <td>12.718568</td>\n",
       "      <td>144.236338</td>\n",
       "      <td>4.415205</td>\n",
       "      <td>0.991824</td>\n",
       "      <td>1.351922</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Poselenie Desjonovskoe</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td>41.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.482746</td>\n",
       "      <td>1.036568</td>\n",
       "      <td>13.459068</td>\n",
       "      <td>1.048962</td>\n",
       "      <td>0.189089</td>\n",
       "      <td>2.640803</td>\n",
       "      <td>...</td>\n",
       "      <td>371</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OwnerOccupier</td>\n",
       "      <td>Tverskoe</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660</th>\n",
       "      <td>34.80</td>\n",
       "      <td>19.80</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.469263</td>\n",
       "      <td>0.930198</td>\n",
       "      <td>11.162378</td>\n",
       "      <td>0.073023</td>\n",
       "      <td>0.766444</td>\n",
       "      <td>0.521349</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Orehovo-Borisovo Juzhnoe</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>63.00</td>\n",
       "      <td>43.80</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.974336</td>\n",
       "      <td>1.172278</td>\n",
       "      <td>14.067336</td>\n",
       "      <td>0.179474</td>\n",
       "      <td>0.143238</td>\n",
       "      <td>0.570409</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Chertanovo Severnoe</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7662 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      full_sq  life_sq  build_year  kitch_sq  metro_min_avto  metro_km_avto  \\\n",
       "0       39.00    20.70      1998.0       8.9        1.258957       0.735908   \n",
       "1       79.20    79.20         0.0       1.0        4.230425       3.444625   \n",
       "2       40.50    25.10      1960.0       4.8        1.585306       1.122214   \n",
       "3       62.80    36.00      2016.0      62.8        7.931398       6.038848   \n",
       "4       40.00    40.00         0.0       1.0        2.152792       1.722233   \n",
       "...       ...      ...         ...       ...             ...            ...   \n",
       "7657    52.20    31.80      1973.0       9.1        1.789207       1.179312   \n",
       "7658    54.09    54.09      2016.0       0.0       15.839451      12.718568   \n",
       "7659    41.08     1.00         1.0       1.0        1.482746       1.036568   \n",
       "7660    34.80    19.80      1977.0       6.4        1.469263       0.930198   \n",
       "7661    63.00    43.80      1973.0       7.1        2.974336       1.172278   \n",
       "\n",
       "      metro_min_walk  kindergarten_km  green_zone_km  industrial_km  ...  \\\n",
       "0           8.830901         0.078502       0.061485       1.205404  ...   \n",
       "1          41.335498         1.192193       0.000000       0.742377  ...   \n",
       "2          13.466563         0.065324       0.580638       0.900408  ...   \n",
       "3          68.559794         3.189083       0.025446       0.466738  ...   \n",
       "4          20.666800         0.897889       0.427248       0.353642  ...   \n",
       "...              ...              ...            ...            ...  ...   \n",
       "7657       13.968183         0.334653       0.199909       0.624466  ...   \n",
       "7658      144.236338         4.415205       0.991824       1.351922  ...   \n",
       "7659       13.459068         1.048962       0.189089       2.640803  ...   \n",
       "7660       11.162378         0.073023       0.766444       0.521349  ...   \n",
       "7661       14.067336         0.179474       0.143238       0.570409  ...   \n",
       "\n",
       "      cafe_count_5000_price_2500  cafe_count_5000_price_high  floor  \\\n",
       "0                              0                           0      2   \n",
       "1                              1                           0      8   \n",
       "2                             11                           0      3   \n",
       "3                              1                           0     17   \n",
       "4                              1                           0     17   \n",
       "...                          ...                         ...    ...   \n",
       "7657                          28                           1     10   \n",
       "7658                           2                           0     14   \n",
       "7659                         371                          26     12   \n",
       "7660                           7                           0      8   \n",
       "7661                          11                           0      5   \n",
       "\n",
       "      max_floor  state   product_type                  sub_area  num_room  \\\n",
       "0             9    3.0     Investment            Juzhnoe Butovo         1   \n",
       "1            17    1.0  OwnerOccupier      Poselenie Vnukovskoe         3   \n",
       "2             5    2.0     Investment                    Perovo         2   \n",
       "3            17    3.0  OwnerOccupier   Poselenie Voskresenskoe         2   \n",
       "4            17    1.0  OwnerOccupier      Poselenie Vnukovskoe         1   \n",
       "...         ...    ...            ...                       ...       ...   \n",
       "7657         12    2.0     Investment                  Kon'kovo         2   \n",
       "7658         14    1.0  OwnerOccupier    Poselenie Desjonovskoe         2   \n",
       "7659         12    1.0  OwnerOccupier                  Tverskoe         1   \n",
       "7660          9    2.0     Investment  Orehovo-Borisovo Juzhnoe         1   \n",
       "7661          5    3.0     Investment       Chertanovo Severnoe         3   \n",
       "\n",
       "      year  month  \n",
       "0     2015      7  \n",
       "1     2015      7  \n",
       "2     2015      7  \n",
       "3     2015      7  \n",
       "4     2015      7  \n",
       "...    ...    ...  \n",
       "7657  2016      5  \n",
       "7658  2016      5  \n",
       "7659  2016      5  \n",
       "7660  2016      5  \n",
       "7661  2016      5  \n",
       "\n",
       "[7662 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_drop_categorical = df.drop(columns=categorical_cols, axis=1)\n",
    "# # Remove rows with outliers\n",
    "# # df_no_outliers = remove_outliers_iqr(df_drop_categorical)\n",
    "\n",
    "# for c in categorical_cols:\n",
    "#     df_no_outliers[c] = df[c]\n",
    "\n",
    "for c in categorical_cols:\n",
    "    df[c] = df[c].astype('category')\n",
    "\n",
    "df_drop_categorical = df.drop(columns=categorical_cols, axis=1)\n",
    "\n",
    "for c in categorical_cols:\n",
    "    df_drop_categorical[c] = df[c]\n",
    "\n",
    "display(df_drop_categorical)\n",
    "\n",
    "# df = pd.get_dummies(df, columns=categorical_cols, dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "C:\\Users\\Yu_Hao\\AppData\\Local\\Temp\\ipykernel_7184\\2096814190.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\Yu_Hao\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "# for c in categorical_cols:\n",
    "#     df_drop_categorical[c] = te_encoder.transform(df_drop_categorical)[c]\n",
    "\n",
    "df_drop_categorical[feature_names] = one_hot_encoder.transform(df_drop_categorical[categorical_cols])\n",
    "\n",
    "df_drop_categorical = df_drop_categorical.drop(categorical_cols, axis=1)\n",
    "\n",
    "df_drop_categorical.to_csv('processed_test.csv', index=False)\n",
    "\n",
    "\n",
    "test_data = xgboost.DMatrix(data=df_drop_categorical, enable_categorical=True)\n",
    "pred = model.predict(test_data)\n",
    "\n",
    "prediction_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'price_doc': pred\n",
    "}).to_csv('xgboost_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
